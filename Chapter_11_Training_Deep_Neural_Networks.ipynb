{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Vanishing/Exploding Gradients Problems\n",
    "This problem occurs when information is lost during backpropagation, i.e. gradients dwindle to nothing or explode as the model diverges. This makes it very difficult to train low layers, as their weights are not being updated properly.\n",
    "\n",
    "This can generally be solved using a better activation function or initialization (or combination thereof).\n",
    "\n",
    "## Nonsaturating activation functions\n",
    "Leaky ReLU implementation - create a leaky ReLU layer just after the layer you want to apply it to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(alpha=0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELU activation implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(10, activation=\"selu\",\n",
    "                           kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "Adds an operation in teh model just before or after the activation function of each hidden layer: zero-center and normalize each input, then scale and shift the result using two new parameter vectors (one for scaling and one for shifting). Lets the model learn the optimal scale and mean of each layer's inputs.\n",
    "\n",
    "Batch normization has become ubiquitous.\n",
    "\n",
    "### Implementing batch normalization with keras\n",
    "This model adds a batch normalization layer before each hidden layer. That's it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try it on mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(200, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 187,196\n",
      "Trainable params: 184,928\n",
      "Non-trainable params: 2,268\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4269 - accuracy: 0.8758 - val_loss: 0.1960 - val_accuracy: 0.9428\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2061 - accuracy: 0.9387 - val_loss: 0.1459 - val_accuracy: 0.9544\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1556 - accuracy: 0.9539 - val_loss: 0.1276 - val_accuracy: 0.9600\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1296 - accuracy: 0.9610 - val_loss: 0.1134 - val_accuracy: 0.9662\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.1116 - accuracy: 0.9656 - val_loss: 0.1073 - val_accuracy: 0.9664\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.0943 - accuracy: 0.9714 - val_loss: 0.1047 - val_accuracy: 0.9690\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0839 - accuracy: 0.9745 - val_loss: 0.0997 - val_accuracy: 0.9720\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0745 - accuracy: 0.9765 - val_loss: 0.1007 - val_accuracy: 0.9694\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.0670 - accuracy: 0.9785 - val_loss: 0.0959 - val_accuracy: 0.9722\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.0600 - accuracy: 0.9815 - val_loss: 0.0965 - val_accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot(figsize=(15, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the results here are similar to what we saw in chapter 10 without batch norm, but we got to them faster! this is what we expected. if early stopping were implemented here, we should have seen a net drop in wall time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping\n",
    "Mitigate exploding gradients by limiting gradients during backpropagation so that they don't exceed a threshold. Most often used in recurrent NNs, since batch normalization is tricky with RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can also use ```clipnorm``` instead of ```clipvalue``` to ensure that clipping does not change the direction of the gradient vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reusing Pretrained Layers\n",
    "## Transfer learning with Keras\n",
    "Example trains model A on a subset of mnist fashion (all except sandals and shirts). Uses model A to start model B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.6960 - accuracy: 0.7886 - val_loss: 0.3815 - val_accuracy: 0.9011\n",
      "Epoch 2/20\n",
      "1394/1394 [==============================] - 5s 4ms/step - loss: 0.3493 - accuracy: 0.9004 - val_loss: 0.2907 - val_accuracy: 0.9188\n",
      "Epoch 3/20\n",
      "1394/1394 [==============================] - 5s 4ms/step - loss: 0.2910 - accuracy: 0.9152 - val_loss: 0.2543 - val_accuracy: 0.9294\n",
      "Epoch 4/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.2616 - accuracy: 0.9242 - val_loss: 0.2331 - val_accuracy: 0.9355\n",
      "Epoch 5/20\n",
      "1394/1394 [==============================] - 5s 4ms/step - loss: 0.2423 - accuracy: 0.9293 - val_loss: 0.2195 - val_accuracy: 0.9387\n",
      "Epoch 6/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.2283 - accuracy: 0.9333 - val_loss: 0.2083 - val_accuracy: 0.9410\n",
      "Epoch 7/20\n",
      "1394/1394 [==============================] - 7s 5ms/step - loss: 0.2168 - accuracy: 0.9371 - val_loss: 0.2000 - val_accuracy: 0.9449\n",
      "Epoch 8/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.2075 - accuracy: 0.9392 - val_loss: 0.1931 - val_accuracy: 0.9474\n",
      "Epoch 9/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.1992 - accuracy: 0.9417 - val_loss: 0.1874 - val_accuracy: 0.9496\n",
      "Epoch 10/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.1919 - accuracy: 0.9442 - val_loss: 0.1821 - val_accuracy: 0.9491\n",
      "Epoch 11/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.1854 - accuracy: 0.9459 - val_loss: 0.1771 - val_accuracy: 0.9525\n",
      "Epoch 12/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.1795 - accuracy: 0.9474 - val_loss: 0.1726 - val_accuracy: 0.9518\n",
      "Epoch 13/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.1736 - accuracy: 0.9497 - val_loss: 0.1692 - val_accuracy: 0.9530\n",
      "Epoch 14/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.1685 - accuracy: 0.9507 - val_loss: 0.1645 - val_accuracy: 0.9540\n",
      "Epoch 15/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.1635 - accuracy: 0.9525 - val_loss: 0.1603 - val_accuracy: 0.9542\n",
      "Epoch 16/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.1589 - accuracy: 0.9534 - val_loss: 0.1567 - val_accuracy: 0.9552\n",
      "Epoch 17/20\n",
      "1394/1394 [==============================] - 8s 6ms/step - loss: 0.1544 - accuracy: 0.9550 - val_loss: 0.1546 - val_accuracy: 0.9557\n",
      "Epoch 18/20\n",
      "1394/1394 [==============================] - 7s 5ms/step - loss: 0.1504 - accuracy: 0.9556 - val_loss: 0.1515 - val_accuracy: 0.9567\n",
      "Epoch 19/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.1462 - accuracy: 0.9576 - val_loss: 0.1477 - val_accuracy: 0.9577\n",
      "Epoch 20/20\n",
      "1394/1394 [==============================] - 6s 4ms/step - loss: 0.1424 - accuracy: 0.9582 - val_loss: 0.1460 - val_accuracy: 0.9587\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\")) # looking for binary classification (shirt vs sandal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that models A and B now share some layers! training model B will impact model A. we need to clone model A to retain it's original weights. (we also have model A saved, so that version will certainly still remain the same too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when we begin to train model B, the new layer we added will possibly ruin the good layers from model A! since it's weights were randomly initialized, the gradients updated there will be large and could be detrimental lower in the network. let's freeze the lower layers to prevent this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\",\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 1.1619 - accuracy: 0.2500 - val_loss: 0.8981 - val_accuracy: 0.4374\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.8353 - accuracy: 0.4750 - val_loss: 0.7179 - val_accuracy: 0.6107\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6744 - accuracy: 0.6400 - val_loss: 0.6138 - val_accuracy: 0.6770\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5794 - accuracy: 0.6800 - val_loss: 0.5250 - val_accuracy: 0.7401\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now allow all layers to be trained and run for more epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=1e-4)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 0s 52ms/step - loss: 0.5211 - accuracy: 0.7150 - val_loss: 0.5209 - val_accuracy: 0.7444\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5161 - accuracy: 0.7150 - val_loss: 0.5168 - val_accuracy: 0.7497\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5113 - accuracy: 0.7150 - val_loss: 0.5125 - val_accuracy: 0.7508\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5067 - accuracy: 0.7250 - val_loss: 0.5088 - val_accuracy: 0.7572\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5020 - accuracy: 0.7350 - val_loss: 0.5048 - val_accuracy: 0.7594\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4974 - accuracy: 0.7550 - val_loss: 0.5013 - val_accuracy: 0.7594\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4931 - accuracy: 0.7650 - val_loss: 0.4974 - val_accuracy: 0.7636\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4886 - accuracy: 0.7750 - val_loss: 0.4939 - val_accuracy: 0.7668\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4843 - accuracy: 0.7800 - val_loss: 0.4899 - val_accuracy: 0.7722\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4799 - accuracy: 0.7800 - val_loss: 0.4864 - val_accuracy: 0.7765\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4758 - accuracy: 0.7850 - val_loss: 0.4827 - val_accuracy: 0.7786\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4715 - accuracy: 0.7900 - val_loss: 0.4790 - val_accuracy: 0.7786\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4673 - accuracy: 0.7950 - val_loss: 0.4762 - val_accuracy: 0.7797\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4635 - accuracy: 0.8000 - val_loss: 0.4727 - val_accuracy: 0.7829\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.4594 - accuracy: 0.8200 - val_loss: 0.4694 - val_accuracy: 0.7893\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4556 - accuracy: 0.8250 - val_loss: 0.4661 - val_accuracy: 0.7925\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 4ms/step - loss: 17.3405 - accuracy: 0.3562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[17.340518951416016, 0.3562162220478058]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "didn't do well at all! if I used the same random seeds as the solutions, I would have gotten a noticeable improvement. the lesson here is that transfer learning isn't always feasible for the network at hand! the solutions note that small dense networks tend to not fare so well with transfer learning since their layers are more specific; compared to a deep CNN, the lower layers in the model above simply aren't as generalizeable or conducive to transfer learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
